{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the Fashion MNIST dataset only contained eight\n",
    "classes—for example, all the classes except for sandal and shirt. Someone built and\n",
    "trained a Keras model on that set and got reasonably good performance (>90% accuracy).\n",
    "Let’s call this model A. You now want to tackle a different task: you have images\n",
    "of sandals and shirts, and you want to train a binary classifier (positive=shirt,\n",
    "negative=sandal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "\n",
    "- X_train_A: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "- X_train_B: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using Dense layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3455 - accuracy: 0.8785 - val_loss: 0.2868 - val_accuracy: 0.8929\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2624 - accuracy: 0.9067 - val_loss: 0.2735 - val_accuracy: 0.9018\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2397 - accuracy: 0.9148 - val_loss: 0.2466 - val_accuracy: 0.9126\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2232 - accuracy: 0.9196 - val_loss: 0.2360 - val_accuracy: 0.9158\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2143 - accuracy: 0.9237 - val_loss: 0.2244 - val_accuracy: 0.9253\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2028 - accuracy: 0.9263 - val_loss: 0.2030 - val_accuracy: 0.9292\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1910 - accuracy: 0.9312 - val_loss: 0.2233 - val_accuracy: 0.9240\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1812 - accuracy: 0.9343 - val_loss: 0.2035 - val_accuracy: 0.9270\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1776 - accuracy: 0.9362 - val_loss: 0.1987 - val_accuracy: 0.9312\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1708 - accuracy: 0.9378 - val_loss: 0.2118 - val_accuracy: 0.9320\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1621 - accuracy: 0.9410 - val_loss: 0.2099 - val_accuracy: 0.9295\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1599 - accuracy: 0.9424 - val_loss: 0.2127 - val_accuracy: 0.9315\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1536 - accuracy: 0.9437 - val_loss: 0.2040 - val_accuracy: 0.9285\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1490 - accuracy: 0.9445 - val_loss: 0.2064 - val_accuracy: 0.9312\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1436 - accuracy: 0.9469 - val_loss: 0.2110 - val_accuracy: 0.9292\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1380 - accuracy: 0.9489 - val_loss: 0.2115 - val_accuracy: 0.9307\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1379 - accuracy: 0.9489 - val_loss: 0.2126 - val_accuracy: 0.9325\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1321 - accuracy: 0.9502 - val_loss: 0.2513 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1286 - accuracy: 0.9523 - val_loss: 0.1948 - val_accuracy: 0.9342\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1279 - accuracy: 0.9521 - val_loss: 0.2076 - val_accuracy: 0.9335\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2356 - accuracy: 0.8750 - val_loss: 0.0663 - val_accuracy: 0.9838\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.1111 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9757\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9807\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.6539e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9817\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.9622e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9848\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2.2314e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5407e-04 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9848\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.2369e-04 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9848\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.1222e-04 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9848\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0319e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9848\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9.5912e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9858\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.9473e-05 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9858\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.3595e-05 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9858\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.9139e-05 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9858\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.4753e-05 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9858\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.1383e-05 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9858\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.7909e-05 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9858\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.5012e-05 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9858\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.2355e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=\"adam\",\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.2804 - accuracy: 0.7150 - val_loss: 1.0422 - val_accuracy: 0.7323\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0990 - accuracy: 0.7200 - val_loss: 0.8851 - val_accuracy: 0.7525\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9321 - accuracy: 0.7350 - val_loss: 0.7503 - val_accuracy: 0.7718\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8045 - accuracy: 0.7500 - val_loss: 0.6347 - val_accuracy: 0.8012\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2839 - accuracy: 0.8950 - val_loss: 0.0795 - val_accuracy: 0.9746\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.0390 - val_accuracy: 0.9838\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9899\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9919\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9949\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.3075e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9949\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.8297e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9949\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.8686e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9949\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.1197e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9949\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.6038e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9970\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.1657e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9970\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.8058e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9970\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.5412e-04 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9970\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.2616e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9970\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.0266e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9970\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.8272e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9970\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=\"adam\",\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04706811532378197, 0.9915000200271606]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019431374967098236, 0.9934999942779541]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
